# visual servo

## 1.Define

1. Move from current to desired robot configuration
2. Control feedback generated by computer vision techniques

## 2.Classification

Controlling Robots using visual information
• Camera location: Eye-in-hand vs. **fixed**
• Camera: mono vs. **stereo**
• Control: **image-based** vs. position-based

## 3.image based visual servo

Determine a error function e,  when the task is achieved, $$e=0$$.

$$e(f)=f-f_d$$     (1)

where $$f_d$$: desired image features, $$f$$: image feature with respect to moving object.

**Note:** $$f$$ is designed in image  parameter space, not task space.

For AI insertion machine 

- if camera is fixed type:

  $$f_d$$: coordinates of  holes.

  $$f$$: coordinates of pins.


- if camera is eye-in-hand type:

  $$f_d$$: coordinates of pins

  $$f$$: coordinates of holes

### A. Basic components

Let $$r$$ represent coordinates of the end-effector and $$\dot{r}$$ represent the corresponding end-effector velocity,  $$f$$   represent a vector of image features, then 

$$\dot{f}=J_v(r)\dot{r}$$     (2)

where $$J_v(r)∈R^{k*6}$$  is called jacobian matrix.

Using (1) and (2)

$$\dot{e}=J_v(r)\dot{r}$$

If we ensure an exponential decoupled decrease of the error($$\dot{e}=-Ke$$)

$$\dot{r}=-KJ_v^{+}(r)e(f)=-KJ_v^{+}(r)(f-f_d)$$

### B. The image jacobian

Note that $$J_v(r)∈R^{k*6}$$

if $$k=6$$, then $$ J_v^{+}=J_v^{-1}$$

if $$k>6$$, then $$ J_v^{+}=J_v^{T}(J_{v}J_{v}^{T})^{-1}$$

if $$k<6$$, then $$\dot{r} =J_v^{+}(\dot{f})+(I-J_v^{+}J_{v})b$$, and all vectors of the form $$(I-J_v^{+}J_{v})b$$ 

lie in the null space of $$J_v$$ 



**In our case**

we use two eye-in-hand cameras, so k=4 , so we use mask to filter some dimensions

### C. An Example Image Jacobian

#### I. The velocity of a  rigid object

In base coordinates, the motion is described by an angular velocity $$Ω(t) = [w_x(t),w_y(t), w_z(t)]^T$$ and a translational velocity $$T(t) = [T_x(t),T_y(t),T_z (t)]^T$$.  Let $$P$$ be a point that is rigidly attached to the end-effector, with base frame coordinates $$[x, y , z]^T$$ . The derivatives of the coordinates of P with respect to base coordinates are given by 

![QQ截图20171220230035](C:\Users\yourenchun\Desktop\视觉伺服\pics\1.png)

which can be written in vector notation as 

![QQ截图20171220230059](C:\Users\yourenchun\Desktop\视觉伺服\pics\2.png)

This can be written concisely in matrix form by noting that the cross product can be represented
in terms of the skew-symmetric matrix 

![QQ截图20171220231948](C:\Users\yourenchun\Desktop\视觉伺服\pics\3.png)

allowing us to write 

![QQ截图20171220231958](C:\Users\yourenchun\Desktop\视觉伺服\pics\4.png)

Together, T and 
 dene what is known in the robotics literature as a velocity screw 

![QQ截图20171220232025](C:\Users\yourenchun\Desktop\视觉伺服\pics\5.png)





Suppose that the end-eector is moving with angular velocity 
(t) and translational velocity T
(as described in Section 2.2) both with respect to the camera frame in a xed camera system. Let
p be a point rigidly attached to the end-eector. The velocity of the point p, expressed relative to
the camera frame, is given by 



![QQ截图20171220232711](C:\Users\yourenchun\Desktop\视觉伺服\pics\6.png)

To simplify notation, let cp = [x; y; z]T . Substituting the perspective projection equations (15)
into (9) { (10) we can write the derivatives of the coordinates of p in terms of the image feature
parameters u; v as 

![QQ截图20171220232059](C:\Users\yourenchun\Desktop\视觉伺服\pics\7.png)

Now, let F = [u; v]T , as above and using the quotient rule 

![QQ截图20171220232114](C:\Users\yourenchun\Desktop\视觉伺服\pics\8.png)

![QQ截图20171220232135](C:\Users\yourenchun\Desktop\视觉伺服\pics\135.png)